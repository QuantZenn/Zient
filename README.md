# ğŸ§  Zient

Zient is a modular framework for extracting financial data, training sentiment models, and comparing them against industry-standard LLMs (like LLaMa, Mixtral, FinBERT, etc.). Designed for flexibility in fine-tuning and batch evaluation, Zient is intended for financial sentiment experimentation at scale.

---

## ğŸ“ Project Structure

```
Zient/
â”‚
â”œâ”€â”€ meta/                  # Metadata or static references
â”œâ”€â”€ models/                # Saved models and checkpoints
â”œâ”€â”€ outputs/               # Prediction results
â””â”€â”€ src/
    â”œâ”€â”€ AutoExtractor/
    â”‚   â”œâ”€â”€ extractors/
    â”‚   â”‚   â””â”€â”€ format_extractor.py
    â”‚   â””â”€â”€ model/
    â”‚       â””â”€â”€ AutoExtractor.py
    â”‚
    â”œâ”€â”€ registry/
    â”‚   â”œâ”€â”€ FormatRegistry.py
    â”‚   â””â”€â”€ formats.json
    â”‚
    â”œâ”€â”€ ModelComparison/
    â”‚   â”œâ”€â”€ compare/
    â”‚   â”‚   â””â”€â”€ compare_model.py
    â”‚   â”œâ”€â”€ config/
    â”‚   â”‚   â”œâ”€â”€ evn.py
    â”‚   â”‚   â””â”€â”€ model_cmp.py
    â”‚   â”œâ”€â”€ Model/
    â”‚   â”‚   â””â”€â”€ ModelComparison.py
    â”‚   â””â”€â”€ ModelWrappers/
    â”‚       â”œâ”€â”€ ChatGPTWrapper.py
    â”‚       â”œâ”€â”€ CommandRPlusWrapper.py
    â”‚       â”œâ”€â”€ DeepSeekWrapper.py
    â”‚       â”œâ”€â”€ FinBERTWrapper.py
    â”‚       â”œâ”€â”€ GemmaWrapper.py
    â”‚       â”œâ”€â”€ LLaMaWrapper.py
    â”‚       â”œâ”€â”€ MistralWrapper.py
    â”‚       â”œâ”€â”€ MixtralWrapper.py
    â”‚       â””â”€â”€ ZientCoreWrapper.py
    â”‚
    â””â”€â”€ ModelTrainer/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ CoreTrainer.py

    main.py             # Entry point for running extraction/training/evaluation
```

---

## ğŸš€ How to Run

### 1. Extract Data

```python
# In main.py
extractor = AutoExtractor()
extractor.extract_all()
```

### 2. Train the Model

```python
trainer = CoreTrainer()
trainer.run()

# Optional: generate and save model from latest checkpoint
# if you didn't finish training previously
# trainer.save_from_latest_checkpoint()
```

### 3. Run Model Comparison

```python
from ModelComparison.compare.compare_model import internal_evaluate

internal_evaluate(
    dataset_path="path/to/test.csv",
    models=None  # or provide specific model names
)
```

ğŸ“„ The results will be saved in:

```
outputs/models/{model_name}_predictions.csv
```

---

## ğŸ’¡ Notes

* Large models like LLaMa, Mixtral, etc., are cached in `llm_cache/` and **excluded** from GitHub.
* Git LFS is used for managing `pytorch_model.bin` files (if required).
* Ensure `test.csv` uses human-readable labels: `positive`, `neutral`, `negative`.

---

## ğŸ“Œ Future Work

* Add sector/ticker-specific fine-tuning support.
* Upload final models and comparison logs to Hugging Face.

---

## ğŸ“Ÿ License

(Include your license type here)

---

## âœï¸ Author

QuantZenn
GitHub: [@QuantZenn](https://github.com/QuantZenn/Zient/)
