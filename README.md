# ğŸ§  Zient â€” Financial Sentiment Analysis Framework

Zient is an end-to-end sentiment analysis framework designed for financial news and data. It supports automated data extraction, model training, and evaluation against various LLMs. 

---

## ğŸ“¦ Project Structure

Zient/
â”œâ”€â”€ meta/ # Metadata or auxiliary files
â”œâ”€â”€ models/ # Trained models and checkpoints
â”œâ”€â”€ outputs/ # Prediction outputs and evaluation results
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ AutoExtractor/ # Raw financial data extractors
â”‚ â”‚ â”œâ”€â”€ extractors/
â”‚ â”‚ â”‚ â””â”€â”€ format_extractor.py
â”‚ â”‚ â””â”€â”€ model/
â”‚ â”‚ â””â”€â”€ AutoExtractor.py
â”‚ â”œâ”€â”€ registry/ # Format registry and definitions
â”‚ â”‚ â”œâ”€â”€ FormatRegistry.py
â”‚ â”‚ â”œâ”€â”€ formats.json
â”‚ â”œâ”€â”€ ModelTrainer/ # Custom model training pipeline
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â””â”€â”€ CoreTrainer.py
â”‚ â”œâ”€â”€ ModelComparison/ # Evaluation pipeline and model wrappers
â”‚ â”‚ â”œâ”€â”€ compare/
â”‚ â”‚ â”‚ â””â”€â”€ compare_model.py
â”‚ â”‚ â”œâ”€â”€ config/
â”‚ â”‚ â”‚ â””â”€â”€ model_cmp.py, evn.py
â”‚ â”‚ â”œâ”€â”€ Model/
â”‚ â”‚ â”‚ â””â”€â”€ ModelComparison.py
â”‚ â”‚ â””â”€â”€ ModelWrappers/
â”‚ â”‚ â”œâ”€â”€ FinBERTWrapper.py
â”‚ â”‚ â”œâ”€â”€ ChatGPTWrapper.py
â”‚ â”‚ â”œâ”€â”€ DeepSeekWrapper.py
â”‚ â”‚ â”œâ”€â”€ ZientCoreWrapper.py
â”‚ â”‚ â”œâ”€â”€ LLaMaWrapper.py
â”‚ â”‚ â”œâ”€â”€ MistralWrapper.py
â”‚ â”‚ â”œâ”€â”€ MixtralWrapper.py
â”‚ â”‚ â”œâ”€â”€ CommandRPlusWrapper.py
â”‚ â”‚ â””â”€â”€ GemmaWrapper.py
â”‚ â””â”€â”€ main.py # Entrypoint for training and evaluation
â”œâ”€â”€ .env
â””â”€â”€ README.md
â””â”€â”€ requiremenr.txt

---

## âš™ï¸ Components

### âœ… AutoExtractor
Extracts and standardizes financial news data into a unified format for training.

- `AutoExtractor.py`: Main class
- `format_extractor.py`: Handles different source formats (e.g., CSV, JSON, TXT, DF)

### âœ… ModelTrainer
Handles model training from cleaned/structured financial data.

- `CoreTrainer.py`: Trains your in-house sentiment classification model (ZientCore)

### âœ… ModelComparison
Evaluates your model against other open-source and API-based LLMs.

Includes wrappers for:

- ğŸ¤– `FinBERT`
- ğŸ¤– `ChatGPT`
- ğŸ¤– `ZientCore`
- ğŸ¤– `DeepSeek`
- ğŸ¤– `LLaMa`
- ğŸ¤– `Mistral`
- ğŸ¤– `Mixtral`
- ğŸ¤– `Command-R+`
- ğŸ¤– `Gemma`

Each wrapper implements `predict_batch()` and supports CSV or dataframe input.

---

## ğŸš€ How to Run

### 1. Extract Data
```bash
# In main.py
extractor = AutoExtractor()
extractor.extract_all()

2. Train the Model
trainer = CoreTrainer()
trainer.run()
#trainer.save_from_latest_checkpoint()  # Optional: generate and save the model from the latest checkpoint if training completed partially and you want to avoid retraining

3. Run Model Comparison
from ModelComparison.compare.compare_model import internal_evaluate

internal_evaluate(dataset_path="path/to/test.csv", models=None)
The result will be saved in outputs/models/{model_name}_predictions.csv

ğŸ§¼ Notes
Large models like LLaMa, Mixtral, etc., are cached in llm_cache/ and excluded from git using .gitignore.

Git LFS is used for managing pytorch_model.bin files (if required).

Ensure test.csv uses human-readable labels (positive, neutral, negative) or the internal logic handles conversion from 0/1/2.

ğŸ“Œ Future Work
Add sector/ticker-specific fine-tuning


ğŸ“œ License


âœï¸ Author
...
GitHub: @QuantZennq